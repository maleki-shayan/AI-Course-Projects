{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45a5e18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import torch\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import urllib.request\n",
    "from gensim.models import KeyedVectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7754ebe",
   "metadata": {},
   "source": [
    "# Making the dataset and preproccessing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19c2709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnappFoodDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        csv_path,\n",
    "        max_len=50,\n",
    "        embed_size=300,\n",
    "    ):\n",
    "        self.max_len = max_len\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        url = \"https://raw.githubusercontent.com/stopwords-iso/stopwords-fa/master/stopwords-fa.txt\"\n",
    "        self.stopwords = set(requests.get(url).text.splitlines())\n",
    "\n",
    "        fixed_lines = []\n",
    "        with open(csv_path, encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                fixed_lines.append(line.replace(\"\\\\t\", \"\\t\"))\n",
    "\n",
    "        fixed_path = \"train_fixed.csv\"\n",
    "        with open(fixed_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.writelines(fixed_lines)\n",
    "\n",
    "        df = pd.read_csv(\n",
    "            fixed_path,\n",
    "            sep=\"\\t\",\n",
    "            names=[\"id\", \"text\", \"label\", \"label_id\"],\n",
    "            header=0,\n",
    "            engine=\"python\",\n",
    "        )\n",
    "\n",
    "        df[\"text\"] = df[\"text\"].astype(str).apply(self.clean_text)\n",
    "\n",
    "        self.labels = torch.tensor(df[\"label_id\"].values, dtype=torch.long)\n",
    "\n",
    "        # print(\"⏳ Loading fastText vectors ...\")\n",
    "        # wv = KeyedVectors.load_word2vec_format(\n",
    "        #     \"cc.fa.300.vec\",\n",
    "        #     binary=False\n",
    "        # )\n",
    "        # print(\"✅ fastText loaded\")\n",
    "\n",
    "        print(\"⏳ Loading fastText vectors ...\")\n",
    "\n",
    "        wv = KeyedVectors.load_word2vec_format(\n",
    "            \"cc.fa.300.vec\",\n",
    "            binary=False,\n",
    "            unicode_errors=\"ignore\"\n",
    "        )\n",
    "\n",
    "        print(\"✅ fastText vectors loaded\")\n",
    "\n",
    "        all_vectors = []\n",
    "\n",
    "        # ---------------- Vectorize (FASTTEXT .VEC) ----------------\n",
    "        for text in tqdm(df[\"text\"], desc=\"Vectorizing (fastText .vec)\"):\n",
    "            words = text.split()[: self.max_len]\n",
    "\n",
    "            vecs = []\n",
    "\n",
    "            for w in words:\n",
    "                if w in wv: \n",
    "                    vecs.append(torch.tensor(wv[w], dtype=torch.float32))\n",
    "\n",
    "            if len(vecs) < self.max_len:\n",
    "                pad = torch.zeros(self.max_len - len(vecs), self.embed_size)\n",
    "                mat = torch.cat([torch.stack(vecs), pad], dim=0) if vecs else pad\n",
    "            else:\n",
    "                mat = torch.stack(vecs[: self.max_len])\n",
    "\n",
    "            mat = mat.t()  # [300, max_len]\n",
    "            all_vectors.append(mat)\n",
    "\n",
    "        self.data = torch.stack(all_vectors)  # [N, 300, 50]\n",
    "\n",
    "        print(\"✅ Dataset ready:\", self.data.shape)\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        text = text.replace(\"ي\", \"ی\").replace(\"ك\", \"ک\")\n",
    "\n",
    "        eng = \"0123456789\"\n",
    "        fa = \"۰۱۲۳۴۵۶۷۸۹\"\n",
    "        for e, f in zip(eng, fa):\n",
    "            text = text.replace(e, f)\n",
    "\n",
    "        text = re.sub(r\"http\\S+\", \"\", text)\n",
    "        text = re.sub(r\"www\\S+\", \"\", text)\n",
    "        text = re.sub(r\"@\\S+\", \"\", text)\n",
    "\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "        tokens = [t for t in text.split() if t not in self.stopwords]\n",
    "        return \" \".join(tokens)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d1f124",
   "metadata": {},
   "source": [
    "as you can see above we made a dataset class in which clean each comment and then implemented two methodes for vectorizing the datas:\n",
    "\n",
    "1: \n",
    "    \n",
    "    using mini multilingual LM from sentance transformers which encodes each comment to a 384d tensor . in this methode we dont just vectorize each word and then vectorize the whole sentance by concatanation , the LM make connections with each words in the sentance and make a much more meaningfull vector for each comment.\n",
    "\n",
    "2: \n",
    "    \n",
    "    the second methode is using the fasttext model and procceed exactly like explained in the projects description."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d8eb68",
   "metadata": {},
   "source": [
    "# Defining the CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ade8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Loading fastText vectors ...\n",
      "✅ fastText vectors loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing (fastText .vec): 100%|██████████| 56700/56700 [00:19<00:00, 2963.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset ready: torch.Size([56700, 300, 50])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [128, 384, 3], expected input[32, 300, 50] to have 384 channels, but got 300 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 58\u001b[39m\n\u001b[32m     54\u001b[39m inputs, labels = inputs.to(device), labels.to(device)\n\u001b[32m     56\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m     62\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mTextCNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# x shape: [Batch, 300, 50]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.relu(x)\n\u001b[32m     24\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.pool(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:375\u001b[39m, in \u001b[36mConv1d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mardin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:370\u001b[39m, in \u001b[36mConv1d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv1d(\n\u001b[32m    360\u001b[39m         F.pad(\n\u001b[32m    361\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    368\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    369\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Given groups=1, weight of size [128, 384, 3], expected input[32, 300, 50] to have 384 channels, but got 300 channels instead"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, embed_size=384, num_classes=2):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=embed_size, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "        # Calculate Linear input size dynamically logic:\n",
    "        # Sequence Length (50) -> Pool(2) -> becomes 25\n",
    "        # Channels (128)\n",
    "        # Flattened size = 128 * 25\n",
    "        self.fc = nn.Linear(128 * 25, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [Batch, 300, 50]\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.flatten(1) \n",
    "        x = self.fc(x) \n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset = SnappFoodDataset('datas/train.csv', max_len=50)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "model = TextCNN(embed_size=300, num_classes=2).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() # Enable Dropout\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "\n",
    "model.eval() # Disable Dropout\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
